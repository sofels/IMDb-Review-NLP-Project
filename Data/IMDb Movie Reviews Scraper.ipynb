{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center> ENSF 612 Project </center>\n",
    "##### <center>Scraping IMDb website </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting selenium\n",
      "  Downloading selenium-4.8.3-py3-none-any.whl (6.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0mm0:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: certifi>=2021.10.8 in /Users/samuelsofela/opt/anaconda3/envs/ensf-ml3/lib/python3.9/site-packages (from selenium) (2022.12.7)\n",
      "Requirement already satisfied: urllib3[socks]~=1.26 in /Users/samuelsofela/opt/anaconda3/envs/ensf-ml3/lib/python3.9/site-packages (from selenium) (1.26.14)\n",
      "Collecting trio-websocket~=0.9\n",
      "  Downloading trio_websocket-0.10.2-py3-none-any.whl (17 kB)\n",
      "Collecting trio~=0.17\n",
      "  Using cached trio-0.22.0-py3-none-any.whl (384 kB)\n",
      "Requirement already satisfied: sniffio in /Users/samuelsofela/opt/anaconda3/envs/ensf-ml3/lib/python3.9/site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Collecting outcome\n",
      "  Using cached outcome-1.2.0-py2.py3-none-any.whl (9.7 kB)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /Users/samuelsofela/opt/anaconda3/envs/ensf-ml3/lib/python3.9/site-packages (from trio~=0.17->selenium) (22.1.0)\n",
      "Requirement already satisfied: idna in /Users/samuelsofela/opt/anaconda3/envs/ensf-ml3/lib/python3.9/site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Requirement already satisfied: sortedcontainers in /Users/samuelsofela/opt/anaconda3/envs/ensf-ml3/lib/python3.9/site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Collecting exceptiongroup>=1.0.0rc9\n",
      "  Using cached exceptiongroup-1.1.1-py3-none-any.whl (14 kB)\n",
      "Collecting async-generator>=1.9\n",
      "  Using cached async_generator-1.10-py3-none-any.whl (18 kB)\n",
      "Collecting wsproto>=0.14\n",
      "  Using cached wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /Users/samuelsofela/opt/anaconda3/envs/ensf-ml3/lib/python3.9/site-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
      "Collecting h11<1,>=0.9.0\n",
      "  Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Installing collected packages: outcome, h11, exceptiongroup, async-generator, wsproto, trio, trio-websocket, selenium\n",
      "Successfully installed async-generator-1.10 exceptiongroup-1.1.1 h11-0.14.0 outcome-1.2.0 selenium-4.8.3 trio-0.22.0 trio-websocket-0.10.2 wsproto-1.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import selenium\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"once\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<urllib3.response.HTTPResponse at 0x7fb5c30193d0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import certifi\n",
    "import urllib3\n",
    "\n",
    "http = urllib3.PoolManager(\n",
    "    cert_reqs=\"CERT_REQUIRED\",\n",
    "    ca_certs=certifi.where()\n",
    ")\n",
    "\n",
    "http.request(\"GET\", \"https://httpbin.org/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samuelsofela/opt/anaconda3/envs/ensf-ml3/lib/python3.9/site-packages/urllib3/connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.imdb.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#URL list from IMDB.  Only pages with atleast 20 reviews.  \n",
    "# After page 351 most movies don't have reviews (and even some on these pages probably don't have enough\n",
    "url_list = [\"https://www.imdb.com/search/title/?title_type=feature&year=2022-01-01,2022-12-31&ref_=adv_prv\"\n",
    "            ,\"https://www.imdb.com/search/title/?title_type=feature&year=2022-01-01,2022-12-31&start=51&ref_=adv_prv\"\n",
    "            ,\"https://www.imdb.com/search/title/?title_type=feature&year=2022-01-01,2022-12-31&start=101&ref_=adv_prv\"\n",
    "            ,\"https://www.imdb.com/search/title/?title_type=feature&year=2022-01-01,2022-12-31&start=151&ref_=adv_prv\"\n",
    "            ,\"https://www.imdb.com/search/title/?title_type=feature&year=2022-01-01,2022-12-31&start=201&ref_=adv_prv\"\n",
    "            ,\"https://www.imdb.com/search/title/?title_type=feature&year=2022-01-01,2022-12-31&start=251&ref_=adv_prv\"\n",
    "            ,\"https://www.imdb.com/search/title/?title_type=feature&year=2022-01-01,2022-12-31&start=301&ref_=adv_prv\"\n",
    "            ,\"https://www.imdb.com/search/title/?title_type=feature&year=2022-01-01,2022-12-31&start=351&ref_=adv_prv\"]\n",
    "\n",
    "\n",
    "\n",
    "#create list to store movie titles in\n",
    "movieURLlist = list()\n",
    "\n",
    "#loop through all the pages and get the end of the hyperlink to each movie.  It usually looks like '/title/tt6710474/' or something like that\n",
    "for pages in url_list:\n",
    "    html=requests.get(pages, verify=False).text\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    #print(soup)\n",
    "\n",
    "    for row in soup.find('div',class_=\"lister-list\").find_all('a',href=re.compile(\"title\")):\n",
    "    #for row in soup.find('div',class_=\"lister-item-content\").find_all('a',href=re.compile(\"title\")):\n",
    "        movieURLlist.append(row['href'])\n",
    "        #print(row['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1204"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking number of movies retrieved\n",
    "len(movieURLlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning link name by removing the \"title\" part of the movie link\n",
    "urllist_regexed = list()\n",
    "\n",
    "for item in movieURLlist:\n",
    "    urllist_regexed.append(re.search(\"^.title.*\\/\",item).group(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove all the duplicates\n",
    "urllist_set = set(urllist_regexed)\n",
    "urllist_list = list(urllist_set)\n",
    "urllist_reviews = list()\n",
    "urllist_main = list()\n",
    "for item in urllist_list:\n",
    "    urllist_reviews.append(\"https://www.imdb.com/\" + item + \"reviews/?ref_=tt_ov_rt\")\n",
    "    urllist_main.append(\"https://www.imdb.com/\" + item)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Started using selemium from here to retrieve review***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting webdriver-manager\n",
      "  Downloading webdriver_manager-3.8.6-py2.py3-none-any.whl (27 kB)\n",
      "Collecting python-dotenv\n",
      "  Using cached python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: requests in /Users/samuelsofela/opt/anaconda3/envs/ensf-ml3/lib/python3.9/site-packages (from webdriver-manager) (2.28.1)\n",
      "Requirement already satisfied: tqdm in /Users/samuelsofela/opt/anaconda3/envs/ensf-ml3/lib/python3.9/site-packages (from webdriver-manager) (4.64.1)\n",
      "Requirement already satisfied: packaging in /Users/samuelsofela/opt/anaconda3/envs/ensf-ml3/lib/python3.9/site-packages (from webdriver-manager) (22.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/samuelsofela/opt/anaconda3/envs/ensf-ml3/lib/python3.9/site-packages (from requests->webdriver-manager) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/samuelsofela/opt/anaconda3/envs/ensf-ml3/lib/python3.9/site-packages (from requests->webdriver-manager) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/samuelsofela/opt/anaconda3/envs/ensf-ml3/lib/python3.9/site-packages (from requests->webdriver-manager) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/samuelsofela/opt/anaconda3/envs/ensf-ml3/lib/python3.9/site-packages (from requests->webdriver-manager) (2.0.4)\n",
      "Installing collected packages: python-dotenv, webdriver-manager\n",
      "Successfully installed python-dotenv-1.0.0 webdriver-manager-3.8.6\n"
     ]
    }
   ],
   "source": [
    "#installing webdriver for selenium \n",
    "#source: https://www.selenium.dev/documentation/webdriver/getting_started/install_drivers/,\n",
    "\n",
    "!pip install webdriver-manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Downloading: 100%|██████████| 8.79M/8.79M [00:00<00:00, 17.2MB/s]\n",
      "/var/folders/18/yxv48zsx08s_dbth29rh3g2r0000gn/T/ipykernel_64358/2161508394.py:5: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(ChromeDriverManager().install())\n"
     ]
    }
   ],
   "source": [
    "# importing and installing selenium 3 driver\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "driver = webdriver.Chrome(ChromeDriverManager().install())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Please note that HTML class tags change in IMDb, and the tags used in this program were the most recent as at the time of scraping IMDb website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "#creating dataframe to store movie data.\n",
    "df_review=pd.DataFrame(columns=['Movie Title','Movie Rating','Movie Genre','Review Date','Review Title', 'Review Content','Reviewer Rating'])\n",
    "for movie_page in urllist_main[0:80]:\n",
    "    #loading movie main page\n",
    "    driver.get(movie_page)\n",
    "    #retrieveing movie ratings from main page\n",
    "    movie_rating = driver.find_element(By.CLASS_NAME, 'sc-e457ee34-1.gvYTvP').text\n",
    "    #retrieving movie genre from main page\n",
    "    mov_genre = driver.find_element(By.CLASS_NAME, 'ipc-chip-list__scroller').find_elements(By.CLASS_NAME, 'ipc-chip__text')\n",
    "    movie_genre = ' '.join([mov_genre[gen].text for gen in range(len(mov_genre))])\n",
    "    \n",
    "    \n",
    "\n",
    "    #Retrieving data from the review page\n",
    "    driver.get(movie_page+\"reviews/?ref_=tt_ov_rt\")\n",
    "    review_count=driver.find_element(By.CLASS_NAME, 'lister').find_element(By.CLASS_NAME, 'header').text\n",
    "    review_count=review_count.split(\" \",2)[0].replace('(','').replace(')','').replace(',','')\n",
    "    if(int(review_count)<50):\n",
    "        continue\n",
    "    driver.implicitly_wait(1)\n",
    "    \n",
    "    page = 1\n",
    "    while page<4: #clicking the 'load more' 4times, which means 100 reviews\n",
    "        try:\n",
    "            #the load more button loads additional 25 reviews on the page \n",
    "            load_more = driver.find_element(By.ID, 'load-more-trigger')\n",
    "            load_more.click()\n",
    "            page +=1\n",
    "        except:\n",
    "            break\n",
    "    review = driver.find_elements(By.CLASS_NAME, 'review-container')\n",
    "    title_hunt = driver.find_element(By.CLASS_NAME, 'parent').find_element(By.TAG_NAME,'a').text\n",
    "    #list to store movie reviews\n",
    "    title=[]\n",
    "    date=[]\n",
    "    content = []\n",
    "    reviewer_rating = []\n",
    "    num_of_reviews=0\n",
    "    for i in range (0,50): #using only the first 50 reviews. We can pick more\n",
    "        try:\n",
    "            #retrieving title of review\n",
    "            rev_title=review[i].find_element(By.CLASS_NAME, 'title').text\n",
    "            #retrieving date of movie review\n",
    "            rev_date=review[i].find_element(By.CLASS_NAME, 'review-date').text\n",
    "            #retrieving rating of the review\n",
    "            rev_rating=review[i].find_element(By.CLASS_NAME, 'ipl-ratings-bar').text.split('/')[0]\n",
    "            #retrieving review of moview\n",
    "            rev_content = review[i].find_element(By.CLASS_NAME,'content').find_element(By.CLASS_NAME,'text.show-more__control').text\n",
    "            if(rev_content==''):\n",
    "                continue\n",
    "            #storing retrieved data in appropriate list\n",
    "            title.append(rev_title)\n",
    "            date.append(rev_date)\n",
    "            content.append(rev_content)\n",
    "            reviewer_rating.append(rev_rating)\n",
    "            num_of_reviews+=1\n",
    "        except:\n",
    "            continue\n",
    "        #ensures only 25 reviews are selected\n",
    "        if(num_of_reviews==25):\n",
    "            break\n",
    "    #storing the review data of one movie into the dataframe\n",
    "    one_reviewset = pd.DataFrame({'Movie Title':title_hunt,\n",
    "                     'Movie Rating':movie_rating,\n",
    "                     'Movie Genre': movie_genre,\n",
    "                     'Review Date':date,\n",
    "                     'Review Title':title,\n",
    "                     'Review Content':content,\n",
    "                     'Reviewer Rating':reviewer_rating\n",
    "               })\n",
    "    pd_review = pd.DataFrame(one_reviewset)\n",
    "    #appending review data of all movies\n",
    "    df_review=df_review.append(one_reviewset, ignore_index=True)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the dataframe into a csv\n",
    "df_review.to_csv('IMDB_Dataset.csv')\n",
    "df_review.head(100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "8c7a34275ec1af5f6d283cb1fe53a13e2f84fe4558f566e0952c6ac227918ff3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
